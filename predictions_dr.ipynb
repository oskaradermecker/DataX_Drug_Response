{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Drug Response Predictions\n",
    "\n",
    "This third and final notebook uses the final matrix created in notebook B (either the \"full\" matrix, or netphix-prefiltered  matrix). It applies several feature reduction methods, namely PCA, RFE, Random Forest based, Lasso based and no feature elimination. If the full matrix is used, it is reduced prior to applying feature selection methods based on variance. Mutations with a variance lower than 0.1 are discared. \n",
    "\n",
    "Four different machine learning models are also applied on the data: Random Forest, MLP, Logistic Regression and SVM.\n",
    "\n",
    "The results are summarized in the table for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset\n",
    "\n",
    "Please note that before running the code, you will need all the GDSC files. They can be found on the drive (https://drive.google.com/drive/u/1/folders/11omvpOttkdZZgv_ppbtcCbojkuVR-D61) or directly on the GDSC website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = False #whether to save the final matrix or not\n",
    "PATH = \"data/Final matrices/\" #where your data is located\n",
    "SAVE = False\n",
    "\n",
    "N_SPLITS = 5\n",
    "\n",
    "DRUG_NAMES = [\"CI-1040\",\n",
    "              \"PD0325901\",\n",
    "              \"Refametinib\",\n",
    "              \"VX-11e\",\n",
    "              \"Afatinib\",\n",
    "              \"Pelitinib\"\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test):\n",
    "    '''\n",
    "    Scales the data\n",
    "    \n",
    "    Input: \n",
    "        X_train: pd.Dataframe\n",
    "        X_test: pd.Dataframe\n",
    "        \n",
    "    Output:\n",
    "        X_train: pd.Dataframe\n",
    "        X_test: pd.Dataframe\n",
    "    '''\n",
    "    feature_names = list(X_train) # Stores the feature names\n",
    "    \n",
    "    sc = StandardScaler()  # Defines the scaler\n",
    "    X_train = pd.DataFrame(sc.fit_transform(X_train))  # Scales the training data\n",
    "    X_test = pd.DataFrame(sc.transform(X_test))  # Scales the validation data\n",
    "\n",
    "    # Replace feature names in the database (they are lost during scaling)\n",
    "    X_train.columns = feature_names\n",
    "    X_test.columns = feature_names\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_feature_reduction(X_train, X_val, y_train, Cst = 0.01):\n",
    "    '''\n",
    "    Performs lasso feature selection\n",
    "    \n",
    "    Input: \n",
    "        X_train: pd.Dataframe, training features\n",
    "        X_val: pd.Dataframe, validation features\n",
    "        y_train: pd.DataFrame, training labels\n",
    "        Cst: float. C term of the Linear SVC used for lasso feature selection.\n",
    "        \n",
    "    Output:\n",
    "        new_X_train: pd.Dataframe\n",
    "        new_X_val: pd.Dataframe\n",
    "    '''\n",
    "    clf = LinearSVC(C = Cst, penalty = \"l1\", dual = False) #SVC(kernel = 'linear', C = Cst)\n",
    "    clf.fit(X_train.values, y_train)\n",
    "    \n",
    "    model = SelectFromModel(clf, prefit=True, threshold=-np.inf, max_features = 300)\n",
    "    new_X_train = model.transform(X_train.values)\n",
    "    new_X_val = model.transform(X_val.values)\n",
    "    \n",
    "    return pd.DataFrame(new_X_train), pd.DataFrame(new_X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feature_reduction(X_train, X_val, y_train, n_estimators = 500):\n",
    "    '''\n",
    "    Performs random forest feature selection\n",
    "    \n",
    "    Input: \n",
    "        X_train: pd.Dataframe, training features\n",
    "        X_val: pd.Dataframe, validation features\n",
    "        y_train: pd.DataFrame, training labels\n",
    "        n_estimators: int. Number of trees in the forest.\n",
    "        \n",
    "    Output:\n",
    "        new_X_train: pd.Dataframe\n",
    "        new_X_val: pd.Dataframe\n",
    "    '''\n",
    "    clf = RandomForestClassifier(n_estimators = n_estimators, n_jobs = -1, class_weight = \"balanced\", random_state = 32)\n",
    "    clf = clf.fit(X_train.values, y_train.values)\n",
    "    \n",
    "    model = SelectFromModel(clf, prefit=True, threshold=-np.inf, max_features = 300)   \n",
    "    new_X_train = model.transform(X_train)\n",
    "    new_X_val = model.transform(X_val)\n",
    "    \n",
    "    importances = clf.feature_importances_\n",
    "    \n",
    "    return pd.DataFrame(new_X_train), pd.DataFrame(new_X_val), importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(my_PCA, nb_components):\n",
    "    '''\n",
    "    Plot the scree plot of the PCA.\n",
    "    \n",
    "    Input: \n",
    "        my_PCA: PCA\n",
    "        n_components: int. Number of principal components selected in the PCA\n",
    "    Output:\n",
    "    '''\n",
    "    fig = plt.figure()\n",
    "    g = sns.lineplot(x = range(1, nb_components+1), y = my_PCA.explained_variance_ratio_)\n",
    "    plt.xlabel('Principal Component')\n",
    "    plt.ylabel('Variance (Component Scores)')\n",
    "    plt.title('Scree Plot of Principal Components')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pca(X, nb_components):\n",
    "    '''\n",
    "    Performs the PCA on X and keeps nb_components.\n",
    "    \n",
    "    Input: \n",
    "        X: pd.Dataframe\n",
    "        nb_components: int. Number of principal components to select in the PCA\n",
    "    Output:\n",
    "        selected: pd.Dataframe. Reduced matrix.\n",
    "        my_pca: PCA object.\n",
    "    '''\n",
    "    my_pca = PCA(n_components = nb_components)\n",
    "    selected = pd.DataFrame(my_pca.fit_transform(np.array(X.values), y=None))\n",
    "    selected.columns = [f\"PC{elem}\" for elem in range(nb_components)]\n",
    "    \n",
    "    return selected, my_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_PCA(X, nb_components, verbose = 5):\n",
    "    '''\n",
    "    Runs the PCA on X using perform_PCA and plots the scree plot.\n",
    "    \n",
    "    Input: \n",
    "        X: pd.Dataframe\n",
    "        nb_components: int. Number of principal components to select in the PCA\n",
    "        verbose: int. Amount of information displayed.\n",
    "    Output:\n",
    "        selected: pd.Dataframe. Reduced matrix.\n",
    "    '''\n",
    "    if verbose > 1:\n",
    "        print(\"Running PCA...\")\n",
    "        print(\"Number of features before PCA: \", len(X.columns))\n",
    "\n",
    "    # Starting PCA\n",
    "    selected, my_pca = perform_pca(X, nb_components)\n",
    "    \n",
    "    # Plotting\n",
    "    if verbose > 0:\n",
    "        plot_pca(my_PCA, nb_components)\n",
    "    \n",
    "    if verbose > 1:\n",
    "        print(\"Number of combined features after PCA: \",len(list(selected)))\n",
    "    \n",
    "    return selected   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(ML_matrix, drug_name, verbose):\n",
    "    '''\n",
    "    Plots the distibution of the drug_name drug in the ML_matrix.\n",
    "    \n",
    "    Input: \n",
    "        ML_matrix: pd.Dataframe\n",
    "        drug_name: string\n",
    "        verbose: int. Amount of information displayed.\n",
    "    Output:\n",
    "    '''\n",
    "    if verbose > 0:\n",
    "        print(f\"\\nDistribution of responses for {drug_name}\")\n",
    "        fig = plt.figure(figsize = (10,6))\n",
    "        sns.distplot(ML_matrix[[drug_name]])\n",
    "        plt.title(\"Plot of the distribution of AUC values for \"+ drug_name)\n",
    "        plt.xlabel(\"AUC\")\n",
    "        plt.ylabel(\"Proportion of cell poplations\")\n",
    "        plt.grid(True);\n",
    "        plt.savefig(\"data/Results/Plots/distribution.png\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_data(ML_matrix, drug_name, verbose):\n",
    "    '''\n",
    "    Categorizes ML_matrix based on the column \"drug_name\". \n",
    "    The data is divided in quartiles. Upper/lower third quartile thresholds were used for discretization. \n",
    "    Everything in the middle is discarded. \n",
    "    See [this](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3995541/) for more information.\n",
    "    Splitting at the median or mean, although keeping more cells, leads to poorer results.\n",
    "        \n",
    "    Input: \n",
    "        ML_matrix: pd.Dataframe\n",
    "        drug_name: string\n",
    "        verbose: int. Amount of information displayed.\n",
    "    Output:\n",
    "        ML_matrix: pd.DataFrame. Categorized matrix.\n",
    "    '''\n",
    "    if verbose > 1:\n",
    "        print(\"The lower threshold used here is the lower third quartile = \", ML_matrix[drug_name].quantile([0.25,0.75])[0.25])\n",
    "        print(\"The upper threshold used here is the uppder third quartile = \", ML_matrix[drug_name].quantile([0.25,0.75])[0.75])\n",
    "    \n",
    "    ML_matrix[\"Response\"] = pd.cut(ML_matrix[drug_name], [np.min(ML_matrix[drug_name]), ML_matrix[drug_name].quantile([0.25,0.75])[0.25], ML_matrix[drug_name].quantile([0.25,0.75])[0.75], np.max(ML_matrix[drug_name])], labels = [\"resistant\",\"medium\", \"sensitive\"])\n",
    "    ML_matrix = ML_matrix.drop([drug_name], axis = 1)\n",
    "    \n",
    "    #Drop all the \"medium\" classes and NaNs\n",
    "    ML_matrix = ML_matrix.drop(ML_matrix[ML_matrix[\"Response\"] == \"medium\"].index)  \n",
    "    \n",
    "    # Convert the response to a float\n",
    "    ML_matrix[\"Response\"] = [0 if x=='resistant' else 1 for x in ML_matrix['Response']]\n",
    "    \n",
    "    # Structure of the feature matrix\n",
    "    print(f\"\\tStructure of the final matrix for {drug_name}:\")\n",
    "    print(\"\\t\\tNumber of resistant cells: \", len(ML_matrix[ML_matrix[\"Response\"] == 0]))\n",
    "    print(\"\\t\\tNumber of sensitive cells: \", len(ML_matrix[ML_matrix[\"Response\"] == 1]))\n",
    "    print(\"\\t\\tTotal number of cells: \", len(ML_matrix.index))\n",
    "    print(f'\\n\\t\\tThe baseline accuracy for {drug_name} is {100*np.round(max(len(ML_matrix[ML_matrix[\"Response\"] == 1])/len(ML_matrix.index),len(ML_matrix[ML_matrix[\"Response\"] == 0])/len(ML_matrix.index)),2)}%')\n",
    "    \n",
    "    return ML_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performances(drug_name, ML_matrix, PATH, N_SPLITS, verbose = 5):\n",
    "    '''\n",
    "    Core function. Categorizes ML_matrix and calculates the performances\n",
    "    over all different feature selection methods and all models.\n",
    "        \n",
    "    Input: \n",
    "        ML_matrix: pd.Dataframe\n",
    "        drug_name: string\n",
    "        PATH: where the data is located\n",
    "        N_SPLITS: int. Number of splits in the cross-validation.\n",
    "        verbose: int. Amount of information displayed.\n",
    "    Output:\n",
    "        final_results: pd.Dataframe. Matrix contaning all final results.\n",
    "    '''\n",
    "    ## Look at the distribution of the response \n",
    "    plot_distribution(ML_matrix, drug_name, verbose)\n",
    "\n",
    "    ## Data Categorisation and feature matrix preparation\n",
    "    print(\"\\nCategorisation of the data...\")\n",
    "    ML_matrix = categorize_data(ML_matrix, drug_name, verbose)\n",
    "    \n",
    "    ## Run the different models and feature selection methods\n",
    "    print(f\"\\nRunning the models with a {N_SPLITS}-fold cross-validation...\")\n",
    "    print(\"Please wait. This can take up to a minute.\")\n",
    "    \n",
    "    # Create our feature and response matrix\n",
    "    X = ML_matrix.drop(\"Response\", axis = 1)\n",
    "    y = ML_matrix[\"Response\"].astype('float64')\n",
    "        \n",
    "    # Define our models\n",
    "    models = {'SVM': SVC(random_state=40, probability = True),\n",
    "              'Logistic Regression':LogisticRegression(solver= 'saga', max_iter=5000, random_state=41),\n",
    "              'MLP': MLPClassifier(max_iter=5000, random_state=42),\n",
    "              'Random Forest': RandomForestClassifier(n_estimators=300, max_depth = 3, max_leaf_nodes = 10, random_state=43)\n",
    "             }  \n",
    "    \n",
    "    # Define the feature selection methods\n",
    "    feature_selection_methods = {\"PCA\":\"Principal Component Analysis\",\n",
    "                                 \"RFE\":\"Recursive Feature Elimination\",\n",
    "                                 \"LASSO\":\"Lasso Feature Selection\",\n",
    "                                 \"RF\": \"Random Forest Feature Selection\",\n",
    "                                 \"None\": \"No feature selection\"\n",
    "                            }\n",
    "    \n",
    "    # Define our final result matrix\n",
    "    final_results = pd.DataFrame(columns = list(models))     \n",
    "    \n",
    "    # Run all models\n",
    "    for feature_selection in feature_selection_methods:\n",
    "        final_results = pretty_run(final_results, X, y, \n",
    "                                   models, \n",
    "                                   N_SPLITS, \n",
    "                                   drug_name, \n",
    "                                   FS = feature_selection, \n",
    "                                   index_name = feature_selection_methods[feature_selection], \n",
    "                                   verbose = verbose)  \n",
    "    \n",
    "    print(f\"All the models were run on {drug_name} successfully!\")\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_run(final_results, X, y, models, N_SPLITS, drug_name, FS, index_name, verbose = 5):\n",
    "    '''\n",
    "    Runs \"run_model\" on all models given in \"models\" and stores the results in final_results\n",
    "        \n",
    "    Input: \n",
    "        final_results: pd.Dataframe. To store the final results.\n",
    "        X: pd.Dataframe. Feature matrix\n",
    "        y: pd.DataFrame. label_matrix\n",
    "        models: dictionary with all the models.\n",
    "        N_SPLITS: int. Number of splits in the cross-validation.\n",
    "        drug_name: string.\n",
    "        FS: string. Feature selection method.\n",
    "        index_name: string. Long name of feature selection method.\n",
    "        verbose: int. Amount of information displayed.\n",
    "    Output:\n",
    "        final_results: pd.Dataframe. Matrix contaning all final results.\n",
    "    '''\n",
    "    for model_name in models:\n",
    "        if verbose > 0:\n",
    "            print('______________________\\n')\n",
    "            print('Running',model_name,'and',index_name)\n",
    "        perf = run_model(X, y, models[model_name], FS = FS, n_splits = N_SPLITS, verbose = verbose)\n",
    "        final_results.loc[index_name,model_name] = perf[2]\n",
    "    \n",
    "    final_results.loc[index_name,\"Drug\"] = drug_name\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_high_variance_mutations(ML_matrix, drug_name, threshold = 0.1):\n",
    "    '''\n",
    "    Removes the features with a variance of less than threshold.\n",
    "        \n",
    "    Input: \n",
    "        ML_matrix: pd.Dataframe\n",
    "        drug_name: string\n",
    "        threshold: float\n",
    "    Output:\n",
    "        reduced_ML_matrix: pd.Dataframe. Reduced matrix.\n",
    "    '''\n",
    "    variance = ML_matrix.var(axis = 0)\n",
    "    \n",
    "    reduced_ML_matrix = ML_matrix.loc[:,variance[variance > threshold].index]\n",
    "    reduced_ML_matrix[drug_name] = ML_matrix[drug_name]\n",
    "    \n",
    "    return reduced_ML_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X, y, clf, FS = \"None\", n_splits = 5, verbose = 5):\n",
    "    '''\n",
    "    Runs the cross validation for the model given by clf on X and y.\n",
    "    \n",
    "    Input:\n",
    "        X: pd.Dataframe. Feature matrix\n",
    "        y: pd.DataFrame. label_matrix\n",
    "        FS: string. Feature selection method.\n",
    "        n_splits: int. Number of splits in the cross-validation.\n",
    "        verbose: int. Amount of information displayed.\n",
    "    Output:\n",
    "        Floats: Average and Std of training accuracy in percent\n",
    "        Floats: Average and Std of validation accuracy in percent\n",
    "        Floats: Average and Std of validation ROC AUC in percent\n",
    "    '''\n",
    "    train_accuracies, val_accuracies, rocs = [],[],[]\n",
    "    \n",
    "    if FS == \"PCA\":\n",
    "        X = run_PCA(X, len(X.columns), verbose = verbose)\n",
    "        \n",
    "    # Define a cross-validation (shuffleSplit here)\n",
    "    ss = ShuffleSplit(n_splits, test_size=0.2, random_state=0)\n",
    "\n",
    "    for count, (training_indices, val_indices) in enumerate(ss.split(X, y), 1):\n",
    "        \n",
    "        if verbose > 1:\n",
    "            print(f'Cross-validation: {count}/{n_splits}')\n",
    "\n",
    "        # Prepare the test and training set     \n",
    "        X_train = X.iloc[training_indices,:]\n",
    "        y_train = y.iloc[training_indices]\n",
    "        X_val = X.iloc[val_indices,:]\n",
    "        y_val = y.iloc[val_indices]\n",
    "        if verbose > 1:\n",
    "            print(f\"The validation set corresponds to roughly {np.round(100*(len(X_val.index)/len(X.index)),2)}% of the total data.\") \n",
    "        \n",
    "        #Scaling the features -- useful for most classifier except RF and co\n",
    "        X_train, X_val = scale_data(X_train, X_val)\n",
    "        \n",
    "        if FS == \"RFE\":            \n",
    "            selector = RFE(estimator = LinearSVC())\n",
    "            selector = selector.fit(X_train, y_train)\n",
    "            X_train = X_train[X_train.columns[selector.support_]]\n",
    "            X_val = X_val[X_val.columns[selector.support_]]\n",
    "        elif FS == \"LASSO\":\n",
    "            X_train, X_val = lasso_feature_reduction(X_train, X_val, y_train)\n",
    "        elif FS == \"RF\":\n",
    "            X_train, X_val, impor = rf_feature_reduction(X_train, X_val, y_train)\n",
    "        elif (FS == \"None\") | (FS == \"PCA\"):\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Check your feature selection method. Enter either 'RFE', LASSO', 'RF' or 'None'.\")\n",
    "            break\n",
    "            return\n",
    "        \n",
    "        # Fit the classifier\n",
    "        clf.fit(X_train.values.tolist(), y_train.values)        \n",
    "        \n",
    "        # Predict the classes\n",
    "        y_pred = clf.predict(X_val.values.tolist())\n",
    "        \n",
    "        # Calculate the performance metrics \n",
    "        train_acc = accuracy_score(y_train.values.tolist(), clf.predict(X_train.values.tolist()))\n",
    "        val_acc = accuracy_score(y_val.values.tolist(), y_pred)\n",
    "        roc_auc = roc_auc_score(y_val.values, clf.predict_proba(X_val.values)[:, 1])\n",
    "        \n",
    "        if verbose > 1:\n",
    "            print(f\"Training accuracy {count}: {train_acc}\")\n",
    "            print(f\"Validation accuracy {count}: {val_acc}\")\n",
    "            print(f\"ROC AUC {count}: {roc_auc}\")\n",
    "    \n",
    "        # Add the performances to their corresponding lists\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "        rocs.append(roc_auc)\n",
    "    if verbose > 1:\n",
    "        print(\"_________________________________________________________________________________\")   \n",
    "    if verbose > 0:\n",
    "        print(f'\\tAverage Training Accuracy: {np.round(100*np.mean(train_accuracies), 2)} +/- {np.round(100*np.std(train_accuracies),2)}%.')\n",
    "        print(f'\\tAverage Validation Accuracy: {np.round(100*np.mean(val_accuracies),2)} +/- {np.round(100*np.std(val_accuracies),2)}%.')\n",
    "        print(f'\\tAverage AUC {np.round(100*np.mean(np.array(rocs)),2)} +/- {np.round(100*np.std(np.array(rocs)),2)}%.')\n",
    "    \n",
    "    return 100*np.mean(train_accuracies), 100*np.std(train_accuracies), 100*np.mean(val_accuracies), 100*np.std(val_accuracies), 100*np.mean(np.array(rocs)), 100*np.std(np.array(rocs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating CI-1040... \n",
      "Number of cells:  758\n",
      "\n",
      "Categorisation of the data...\n",
      "\tStructure of the final matrix for CI-1040:\n",
      "\t\tNumber of resistant cells:  189\n",
      "\t\tNumber of sensitive cells:  191\n",
      "\t\tTotal number of cells:  380\n",
      "\n",
      "\t\tThe baseline accuracy for CI-1040 is 50.0%\n",
      "\n",
      "Running the models with a 5-fold cross-validation...\n",
      "Please wait. This can take up to a minute.\n",
      "All the models were run on CI-1040 successfully!\n",
      "_________________________________________________________________________________________________________\n",
      "Investigating PD0325901... \n",
      "Number of cells:  759\n",
      "\n",
      "Categorisation of the data...\n",
      "\tStructure of the final matrix for PD0325901:\n",
      "\t\tNumber of resistant cells:  189\n",
      "\t\tNumber of sensitive cells:  191\n",
      "\t\tTotal number of cells:  380\n",
      "\n",
      "\t\tThe baseline accuracy for PD0325901 is 50.0%\n",
      "\n",
      "Running the models with a 5-fold cross-validation...\n",
      "Please wait. This can take up to a minute.\n",
      "All the models were run on PD0325901 successfully!\n",
      "_________________________________________________________________________________________________________\n",
      "Investigating Refametinib... \n",
      "Number of cells:  813\n",
      "\n",
      "Categorisation of the data...\n",
      "\tStructure of the final matrix for Refametinib:\n",
      "\t\tNumber of resistant cells:  203\n",
      "\t\tNumber of sensitive cells:  204\n",
      "\t\tTotal number of cells:  407\n",
      "\n",
      "\t\tThe baseline accuracy for Refametinib is 50.0%\n",
      "\n",
      "Running the models with a 5-fold cross-validation...\n",
      "Please wait. This can take up to a minute.\n",
      "All the models were run on Refametinib successfully!\n",
      "_________________________________________________________________________________________________________\n",
      "Investigating VX-11e... \n",
      "Number of cells:  831\n",
      "\n",
      "Categorisation of the data...\n",
      "\tStructure of the final matrix for VX-11e:\n",
      "\t\tNumber of resistant cells:  207\n",
      "\t\tNumber of sensitive cells:  209\n",
      "\t\tTotal number of cells:  416\n",
      "\n",
      "\t\tThe baseline accuracy for VX-11e is 50.0%\n",
      "\n",
      "Running the models with a 5-fold cross-validation...\n",
      "Please wait. This can take up to a minute.\n",
      "All the models were run on VX-11e successfully!\n",
      "_________________________________________________________________________________________________________\n",
      "Investigating Afatinib... \n",
      "Number of cells:  840\n",
      "\n",
      "Categorisation of the data...\n",
      "\tStructure of the final matrix for Afatinib:\n",
      "\t\tNumber of resistant cells:  209\n",
      "\t\tNumber of sensitive cells:  211\n",
      "\t\tTotal number of cells:  420\n",
      "\n",
      "\t\tThe baseline accuracy for Afatinib is 50.0%\n",
      "\n",
      "Running the models with a 5-fold cross-validation...\n",
      "Please wait. This can take up to a minute.\n",
      "All the models were run on Afatinib successfully!\n",
      "_________________________________________________________________________________________________________\n",
      "Investigating Pelitinib... \n",
      "Number of cells:  832\n",
      "\n",
      "Categorisation of the data...\n",
      "\tStructure of the final matrix for Pelitinib:\n",
      "\t\tNumber of resistant cells:  207\n",
      "\t\tNumber of sensitive cells:  209\n",
      "\t\tTotal number of cells:  416\n",
      "\n",
      "\t\tThe baseline accuracy for Pelitinib is 50.0%\n",
      "\n",
      "Running the models with a 5-fold cross-validation...\n",
      "Please wait. This can take up to a minute.\n",
      "All the models were run on Pelitinib successfully!\n",
      "_________________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>MLP</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug</th>\n",
       "      <th>Methods</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">CI-1040</th>\n",
       "      <th>Principal Component Analysis</th>\n",
       "      <td>75.7895</td>\n",
       "      <td>76.5789</td>\n",
       "      <td>76.5789</td>\n",
       "      <td>75.7895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recursive Feature Elimination</th>\n",
       "      <td>76.3158</td>\n",
       "      <td>76.3158</td>\n",
       "      <td>76.3158</td>\n",
       "      <td>76.3158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Feature Selection</th>\n",
       "      <td>75.7895</td>\n",
       "      <td>76.5789</td>\n",
       "      <td>76.5789</td>\n",
       "      <td>76.3158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Feature Selection</th>\n",
       "      <td>75.7895</td>\n",
       "      <td>76.5789</td>\n",
       "      <td>76.5789</td>\n",
       "      <td>76.3158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No feature selection</th>\n",
       "      <td>75.7895</td>\n",
       "      <td>76.5789</td>\n",
       "      <td>76.5789</td>\n",
       "      <td>76.3158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">PD0325901</th>\n",
       "      <th>Principal Component Analysis</th>\n",
       "      <td>74.4737</td>\n",
       "      <td>74.4737</td>\n",
       "      <td>74.4737</td>\n",
       "      <td>74.4737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recursive Feature Elimination</th>\n",
       "      <td>71.0526</td>\n",
       "      <td>71.0526</td>\n",
       "      <td>71.0526</td>\n",
       "      <td>71.0526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Feature Selection</th>\n",
       "      <td>74.4737</td>\n",
       "      <td>74.4737</td>\n",
       "      <td>74.7368</td>\n",
       "      <td>73.9474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Feature Selection</th>\n",
       "      <td>74.4737</td>\n",
       "      <td>74.4737</td>\n",
       "      <td>74.7368</td>\n",
       "      <td>73.9474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No feature selection</th>\n",
       "      <td>74.4737</td>\n",
       "      <td>74.4737</td>\n",
       "      <td>74.7368</td>\n",
       "      <td>73.9474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Refametinib</th>\n",
       "      <th>Principal Component Analysis</th>\n",
       "      <td>78.2927</td>\n",
       "      <td>79.5122</td>\n",
       "      <td>78.7805</td>\n",
       "      <td>77.3171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recursive Feature Elimination</th>\n",
       "      <td>77.8049</td>\n",
       "      <td>78.2927</td>\n",
       "      <td>78.2927</td>\n",
       "      <td>77.8049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Feature Selection</th>\n",
       "      <td>78.2927</td>\n",
       "      <td>79.5122</td>\n",
       "      <td>78.2927</td>\n",
       "      <td>78.7805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Feature Selection</th>\n",
       "      <td>78.2927</td>\n",
       "      <td>79.5122</td>\n",
       "      <td>78.2927</td>\n",
       "      <td>78.7805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No feature selection</th>\n",
       "      <td>78.2927</td>\n",
       "      <td>79.5122</td>\n",
       "      <td>78.2927</td>\n",
       "      <td>78.7805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">VX-11e</th>\n",
       "      <th>Principal Component Analysis</th>\n",
       "      <td>70.2381</td>\n",
       "      <td>71.6667</td>\n",
       "      <td>70.4762</td>\n",
       "      <td>70.4762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recursive Feature Elimination</th>\n",
       "      <td>67.381</td>\n",
       "      <td>67.381</td>\n",
       "      <td>67.381</td>\n",
       "      <td>66.9048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Feature Selection</th>\n",
       "      <td>69.0476</td>\n",
       "      <td>71.6667</td>\n",
       "      <td>69.2857</td>\n",
       "      <td>70.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Feature Selection</th>\n",
       "      <td>69.0476</td>\n",
       "      <td>71.6667</td>\n",
       "      <td>69.2857</td>\n",
       "      <td>70.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No feature selection</th>\n",
       "      <td>69.0476</td>\n",
       "      <td>71.6667</td>\n",
       "      <td>69.2857</td>\n",
       "      <td>70.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Afatinib</th>\n",
       "      <th>Principal Component Analysis</th>\n",
       "      <td>61.1905</td>\n",
       "      <td>61.6667</td>\n",
       "      <td>61.4286</td>\n",
       "      <td>61.1905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recursive Feature Elimination</th>\n",
       "      <td>53.0952</td>\n",
       "      <td>53.0952</td>\n",
       "      <td>53.0952</td>\n",
       "      <td>53.0952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Feature Selection</th>\n",
       "      <td>61.1905</td>\n",
       "      <td>61.6667</td>\n",
       "      <td>61.6667</td>\n",
       "      <td>61.9048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Feature Selection</th>\n",
       "      <td>61.1905</td>\n",
       "      <td>61.6667</td>\n",
       "      <td>61.6667</td>\n",
       "      <td>61.9048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No feature selection</th>\n",
       "      <td>61.1905</td>\n",
       "      <td>61.6667</td>\n",
       "      <td>61.6667</td>\n",
       "      <td>61.9048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Pelitinib</th>\n",
       "      <th>Principal Component Analysis</th>\n",
       "      <td>59.7619</td>\n",
       "      <td>55.9524</td>\n",
       "      <td>59.2857</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recursive Feature Elimination</th>\n",
       "      <td>55.4762</td>\n",
       "      <td>55</td>\n",
       "      <td>56.1905</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Feature Selection</th>\n",
       "      <td>59.7619</td>\n",
       "      <td>55.9524</td>\n",
       "      <td>59.2857</td>\n",
       "      <td>59.5238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Feature Selection</th>\n",
       "      <td>59.7619</td>\n",
       "      <td>55.9524</td>\n",
       "      <td>59.2857</td>\n",
       "      <td>59.5238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No feature selection</th>\n",
       "      <td>59.7619</td>\n",
       "      <td>55.9524</td>\n",
       "      <td>59.2857</td>\n",
       "      <td>59.5238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 SVM Logistic Regression  \\\n",
       "Drug        Methods                                                        \n",
       "CI-1040     Principal Component Analysis     75.7895             76.5789   \n",
       "            Recursive Feature Elimination    76.3158             76.3158   \n",
       "            Lasso Feature Selection          75.7895             76.5789   \n",
       "            Random Forest Feature Selection  75.7895             76.5789   \n",
       "            No feature selection             75.7895             76.5789   \n",
       "PD0325901   Principal Component Analysis     74.4737             74.4737   \n",
       "            Recursive Feature Elimination    71.0526             71.0526   \n",
       "            Lasso Feature Selection          74.4737             74.4737   \n",
       "            Random Forest Feature Selection  74.4737             74.4737   \n",
       "            No feature selection             74.4737             74.4737   \n",
       "Refametinib Principal Component Analysis     78.2927             79.5122   \n",
       "            Recursive Feature Elimination    77.8049             78.2927   \n",
       "            Lasso Feature Selection          78.2927             79.5122   \n",
       "            Random Forest Feature Selection  78.2927             79.5122   \n",
       "            No feature selection             78.2927             79.5122   \n",
       "VX-11e      Principal Component Analysis     70.2381             71.6667   \n",
       "            Recursive Feature Elimination     67.381              67.381   \n",
       "            Lasso Feature Selection          69.0476             71.6667   \n",
       "            Random Forest Feature Selection  69.0476             71.6667   \n",
       "            No feature selection             69.0476             71.6667   \n",
       "Afatinib    Principal Component Analysis     61.1905             61.6667   \n",
       "            Recursive Feature Elimination    53.0952             53.0952   \n",
       "            Lasso Feature Selection          61.1905             61.6667   \n",
       "            Random Forest Feature Selection  61.1905             61.6667   \n",
       "            No feature selection             61.1905             61.6667   \n",
       "Pelitinib   Principal Component Analysis     59.7619             55.9524   \n",
       "            Recursive Feature Elimination    55.4762                  55   \n",
       "            Lasso Feature Selection          59.7619             55.9524   \n",
       "            Random Forest Feature Selection  59.7619             55.9524   \n",
       "            No feature selection             59.7619             55.9524   \n",
       "\n",
       "                                                 MLP Random Forest  \n",
       "Drug        Methods                                                 \n",
       "CI-1040     Principal Component Analysis     76.5789       75.7895  \n",
       "            Recursive Feature Elimination    76.3158       76.3158  \n",
       "            Lasso Feature Selection          76.5789       76.3158  \n",
       "            Random Forest Feature Selection  76.5789       76.3158  \n",
       "            No feature selection             76.5789       76.3158  \n",
       "PD0325901   Principal Component Analysis     74.4737       74.4737  \n",
       "            Recursive Feature Elimination    71.0526       71.0526  \n",
       "            Lasso Feature Selection          74.7368       73.9474  \n",
       "            Random Forest Feature Selection  74.7368       73.9474  \n",
       "            No feature selection             74.7368       73.9474  \n",
       "Refametinib Principal Component Analysis     78.7805       77.3171  \n",
       "            Recursive Feature Elimination    78.2927       77.8049  \n",
       "            Lasso Feature Selection          78.2927       78.7805  \n",
       "            Random Forest Feature Selection  78.2927       78.7805  \n",
       "            No feature selection             78.2927       78.7805  \n",
       "VX-11e      Principal Component Analysis     70.4762       70.4762  \n",
       "            Recursive Feature Elimination     67.381       66.9048  \n",
       "            Lasso Feature Selection          69.2857       70.7143  \n",
       "            Random Forest Feature Selection  69.2857       70.7143  \n",
       "            No feature selection             69.2857       70.7143  \n",
       "Afatinib    Principal Component Analysis     61.4286       61.1905  \n",
       "            Recursive Feature Elimination    53.0952       53.0952  \n",
       "            Lasso Feature Selection          61.6667       61.9048  \n",
       "            Random Forest Feature Selection  61.6667       61.9048  \n",
       "            No feature selection             61.6667       61.9048  \n",
       "Pelitinib   Principal Component Analysis     59.2857            60  \n",
       "            Recursive Feature Elimination    56.1905            55  \n",
       "            Lasso Feature Selection          59.2857       59.5238  \n",
       "            Random Forest Feature Selection  59.2857       59.5238  \n",
       "            No feature selection             59.2857       59.5238  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_all_drugs(DRUG_NAMES, PATH, N_SPLITS, Netphix = False, verbose = 5):\n",
    "    '''\n",
    "    Compilation function. Runs the whole analysis on all the drugs in DRUG_NAMES.\n",
    "    \n",
    "    Input:\n",
    "        DRUG_NAMES: dictionary or list with all the drugs\n",
    "        PATH: string. where the data is stored.\n",
    "        N_SPLITS: int. Number of splits in the cross-validation.\n",
    "        Netphix: boold. whether the whole or prefiltered dataframe should be imported\n",
    "        verbose: int. Amount of information displayed.\n",
    "    Output:\n",
    "        final_results: pd.Dataframe. All aggregated final results.\n",
    "    \n",
    "    '''\n",
    "    final_results = pd.DataFrame()\n",
    "    \n",
    "    for drug in DRUG_NAMES:\n",
    "\n",
    "        print(f\"Investigating {drug}... \")\n",
    "        \n",
    "        name = drug\n",
    "        if not Netphix:\n",
    "            name = drug + \"_full\"\n",
    "        \n",
    "        # Read the corresponding ML matrix\n",
    "        ML_matrix = pd.read_csv(PATH + name + \".csv\")\n",
    "        ML_matrix.set_index(\"Cell_line\", inplace = True)\n",
    "        ML_matrix = ML_matrix.dropna()\n",
    "        \n",
    "        if not Netphix:\n",
    "            ML_matrix = select_high_variance_mutations(ML_matrix, drug)\n",
    "        \n",
    "        print(\"Number of cells: \", len(ML_matrix.index))\n",
    "        if verbose > 3:\n",
    "            ML_matrix.head() #Show the head of the dataframe for that drug\n",
    "\n",
    "        results_drug = calculate_performances(drug, ML_matrix, PATH, N_SPLITS, verbose = verbose)\n",
    "        \n",
    "        final_results = pd.concat([final_results,results_drug])\n",
    "                                          \n",
    "        print(\"_________________________________________________________________________________________________________\")\n",
    "        \n",
    "    final_results.index.name = \"Methods\"\n",
    "    \n",
    "    return final_results.reset_index(drop=False).set_index([\"Drug\",\"Methods\"])\n",
    "                                          \n",
    "final_results = run_all_drugs(DRUG_NAMES, PATH, N_SPLITS, Netphix = True, verbose = 0)\n",
    "display(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    final_results.to_csv(f'data/Results/Netphix_results.csv', index_label = [\"Drug\",\"Methods\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset\n",
    "\n",
    "Please note that before running the code, you will need all the GDSC files. They can be found on the drive (https://drive.google.com/drive/u/1/folders/11omvpOttkdZZgv_ppbtcCbojkuVR-D61) or directly on the GDSC website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE = \"AUC\" #how the sensitivity of the drug is computed; other option: \"AUC\" \n",
    "SAVE = False #whether to save the final matrix or not\n",
    "PATH = \"data/Final matrices/\" #where your data is located\n",
    "\n",
    "N_SPLITS = 5\n",
    "DRUG_NAMES = {\"CI-1040\": [\"MYC_mut\",\"RB1_mut\",\"ERBB2_amp\",\"BRAF_mut\",\"KRAS_mut\",\"NRAS_mut\"],\n",
    "              \"PD0325901\": [\"MYC_mut\",\"RB1_mut\",\"ERBB2_amp\",\"BRAF_mut\",\"KRAS_mut\",\"NRAS_mut\"],\n",
    "              \"Refametinib\":[\"MYC_mut\",\"RB1_mut\",\"ERBB2_amp\",\"BRAF_mut\",\"KRAS_mut\",\"NRAS_mut\"],\n",
    "              \"VX-11e\":[\"RB1_mut\",\"ERBB2_amp\",\"CCND1_amp\",\"BRAF_mut\",\"KRAS_mut\",\"NRAS_mut\"],\n",
    "              \"Afatinib\":[\"KRAS_mut\",\"NRAS_mut\",\"EGFR_amp\",\"ERBB2_amp\",\"FOXP3_del\"],\n",
    "              \"Pelitinib\":[\"BRAF_mut\",\"RB1_mut\",\"MAPK1_del\",\"MYC_mut\",\"EGFR_mut\",\"CDKN1B_del\"]\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test):\n",
    "    \n",
    "    feature_names = list(X_train) # Store the feature names\n",
    "    \n",
    "    sc = StandardScaler()  # Defines the scaler\n",
    "    X_train = pd.DataFrame(sc.fit_transform(X_train))  # Scales the training data\n",
    "    X_test = pd.DataFrame(sc.transform(X_test))  # Scales the validation data\n",
    "\n",
    "    # Replace feature names in the database (they are lost during scaling)\n",
    "    X_train.columns = feature_names\n",
    "    X_test.columns = feature_names\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_feature_reduction(X_train, X_val, y_train, Cst = 0.01):\n",
    "    \n",
    "    clf = LinearSVC(C = Cst, penalty = \"l1\", dual = False) #SVC(kernel = 'linear', C = Cst)\n",
    "    clf.fit(X_train.values, y_train)\n",
    "    \n",
    "    model = SelectFromModel(clf, prefit=True, threshold=-np.inf, max_features = 300)\n",
    "    new_X_train = model.transform(X_train.values)\n",
    "    new_X_val = model.transform(X_val.values)\n",
    "    \n",
    "    return pd.DataFrame(new_X_train), pd.DataFrame(new_X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feature_reduction(X_train, X_val, y_train, N_ESTIMATORS = 500):\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators = N_ESTIMATORS, n_jobs = -1, class_weight = \"balanced\", random_state = 32)\n",
    "    clf = clf.fit(X_train.values, y_train.values)\n",
    "    \n",
    "    model = SelectFromModel(clf, prefit=True, threshold=-np.inf, max_features = 300)   \n",
    "    new_X_train = model.transform(X_train)\n",
    "    new_X_val = model.transform(X_val)\n",
    "    \n",
    "    importances = clf.feature_importances_\n",
    "    #std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0) --> std dev but we don't use it anyway\n",
    "    \n",
    "    return pd.DataFrame(new_X_train), pd.DataFrame(new_X_val), importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_PCA(X, NB_COMPONENTS, kf = 5, verbose = 5):\n",
    "\n",
    "    if verbose > 1:\n",
    "        print(\"Running PCA...\")\n",
    "        print(\"Number of features before PCA: \", len(X.columns))\n",
    "\n",
    "    # Starting PCA\n",
    "    my_PCA = PCA(n_components=NB_COMPONENTS)\n",
    "    reduced_X = pd.DataFrame(my_PCA.fit_transform(np.array(X.values), y=None))\n",
    "    reduced_X.columns = [f\"PC{elem}\" for elem in range(NB_COMPONENTS)]\n",
    "    \n",
    "    # Plotting\n",
    "    if verbose > 0:\n",
    "        fig = plt.figure()\n",
    "        g = sns.lineplot(x = range(1, NB_COMPONENTS+1), y = my_PCA.explained_variance_ratio_)\n",
    "        plt.xlabel('Principal Component')\n",
    "        plt.ylabel('Variance (Component Scores)')\n",
    "        plt.title('Screen Plot of Principal Components')\n",
    "        plt.show(); \n",
    "    \n",
    "    if verbose > 1:\n",
    "        print(\"Number of combined features after PCA: \",len(list(reduced_X)))\n",
    "    \n",
    "    return reduced_X   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performances(DRUG_NAME, ML_matrix, PATH, SCORE, N_SPLITS, verbose = 5):\n",
    "    \n",
    "    ## Look at the distribution of the response\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print(f\"\\nDistribution of responses for {DRUG_NAME}\")\n",
    "        fig = plt.figure(figsize = (10,6))\n",
    "        sns.distplot(ML_matrix[[DRUG_NAME]])\n",
    "        plt.title(\"Plot of the distribution of AUC values for \"+ DRUG_NAME)\n",
    "        plt.xlabel(\"AUC\")\n",
    "        plt.ylabel(\"Proportion of cell poplations\")\n",
    "        plt.grid(True);\n",
    "        plt.show()\n",
    "\n",
    "    #_______________________________________________________________________________________________________#\n",
    "    \n",
    "    ## Data Categorisation and feature matrix preparation\n",
    "    print(\"\\nCategorisation of the data...\")\n",
    "    # The data is divided in quartiles. Upper/lower third quartile thresholds were used for discretization. \n",
    "    # Everything that is in the middle is discarded. See [this](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3995541/) paper.\n",
    "    # Splitting at the median or mean, although keeping more cells, leads to poorer results.\n",
    "    \n",
    "    if verbose > 1:\n",
    "        print(\"The lower threshold used here is the lower third quartile = \", ML_matrix[DRUG_NAME].quantile([0.25,0.75])[0.25])\n",
    "        print(\"The upper threshold used here is the uppder third quartile = \", ML_matrix[DRUG_NAME].quantile([0.25,0.75])[0.75])\n",
    "    ML_matrix[\"Response\"] = pd.cut(ML_matrix[DRUG_NAME], [np.min(ML_matrix[DRUG_NAME]), ML_matrix[DRUG_NAME].quantile([0.25,0.75])[0.25], ML_matrix[DRUG_NAME].quantile([0.25,0.75])[0.75], np.max(ML_matrix[DRUG_NAME])], labels = [\"sensitive\",\"medium\", \"resistant\"])\n",
    "    ML_matrix = ML_matrix.drop([DRUG_NAME], axis = 1)\n",
    "    \n",
    "    #Drop all the \"medium\" classes and NaNs\n",
    "    ML_matrix = ML_matrix.drop(ML_matrix[ML_matrix[\"Response\"] == \"medium\"].index)\n",
    "    ML_matrix = ML_matrix.dropna()  \n",
    "    \n",
    "    # Convert the response to a float\n",
    "    ML_matrix[\"Response\"] = [0 if x=='resistant' else 1 for x in ML_matrix['Response']]\n",
    "    \n",
    "    # Structure of the feature matrix\n",
    "    print(f\"\\tStructure of the final matrix for {DRUG_NAME}:\")\n",
    "    print(\"\\t\\tNumber of resistant cells: \", len(ML_matrix[ML_matrix[\"Response\"] == 0]))\n",
    "    print(\"\\t\\tNumber of sensitive cells: \", len(ML_matrix[ML_matrix[\"Response\"] == 1]))\n",
    "    print(\"\\t\\tTotal number of cells: \", len(ML_matrix.index))\n",
    "    print(f'\\n\\t\\tThe baseline accuracy for {DRUG_NAME} is {100*np.round(len(ML_matrix[ML_matrix[\"Response\"] == 1])/len(ML_matrix.index),2)}%')\n",
    "    \n",
    "    #_______________________________________________________________________________________________________#\n",
    "    \n",
    "    ## Run the different models and feature selection methods\n",
    "    \n",
    "    print(f\"\\nRunning the models with a {N_SPLITS}-fold cross-validation...\")\n",
    "    print(\"Please wait. This can take up to a minute.\")\n",
    "    \n",
    "    # Create our feature and response matrix\n",
    "    X = ML_matrix.drop(\"Response\", axis = 1)\n",
    "    y = ML_matrix[\"Response\"].astype('float64')\n",
    "        \n",
    "    # Define our models    \n",
    "    models = [SVC(random_state=40),\n",
    "              LogisticRegression(solver= 'saga', max_iter=5000, random_state=41),\n",
    "              MLPClassifier(max_iter=5000, random_state=42),\n",
    "              RandomForestClassifier(n_estimators=300, max_depth = 3, max_leaf_nodes = 10, random_state=43)]\n",
    "    \n",
    "    model_names = ['SVM', 'Logistic Regression', 'MLP', 'Random Forest']\n",
    "    \n",
    "    # Define our final result matrix\n",
    "    final_results = pd.DataFrame(columns = model_names)     \n",
    "          \n",
    "    # Run all models\n",
    "    # Run PCA\n",
    "    final_results = pretty_run(final_results, X, y, models, model_names, N_SPLITS, DRUG_NAME, FS = \"PCA\", index_name = \"Principal Component Analysis\", verbose = verbose)  \n",
    "          \n",
    "    # Run RFE\n",
    "    final_results = pretty_run(final_results, X, y, models, model_names, N_SPLITS, DRUG_NAME, FS = \"RFE\", index_name = \"Recursive Feature Elimination\", verbose = verbose)\n",
    "    \n",
    "    # Run Lasso Feature Selection\n",
    "    final_results = pretty_run(final_results, X, y, models, model_names, N_SPLITS, DRUG_NAME, FS = \"LASSO\", index_name = \"Lasso Feature Selection\", verbose = verbose)\n",
    "          \n",
    "    # Run Random Forest Feature Selection\n",
    "    final_results = pretty_run(final_results, X, y, models, model_names, N_SPLITS, DRUG_NAME, FS = \"RF\", index_name = \"Random Forest Feature Selection\", verbose = verbose)\n",
    "          \n",
    "    # Run with no feature selection\n",
    "    final_results = pretty_run(final_results, X, y, models, model_names, N_SPLITS, DRUG_NAME, FS = \"None\", index_name = \"No feature selection\", verbose = verbose)\n",
    "    \n",
    "    print(f\"All the models were run on {DRUG_NAME} successfully!\")\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_run(final_results, X, y, models, model_names, N_SPLITS, DRUG_NAME, FS, index_name, verbose = 5):\n",
    "    \n",
    "    for i in range(len(models)):\n",
    "        if verbose > 0:\n",
    "            print('______________________\\n')\n",
    "            print('Running',model_names[i],'and',index_name)\n",
    "        perf = run_model(X, y, models[i], FS = FS, n_splits = N_SPLITS, verbose = verbose)\n",
    "        final_results.loc[index_name,model_names[i]] = perf[2]\n",
    "    \n",
    "    final_results.loc[index_name,\"Drug\"] = DRUG_NAME\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X, y, clf, FS = \"None\", n_splits = 5, verbose = 5):\n",
    "    \n",
    "    train_accuracies, val_accuracies, rocs = [],[],[]\n",
    "    \n",
    "    if FS == \"PCA\":\n",
    "        X = run_PCA(X, NB_COMPONENTS = len(X.columns), verbose = verbose)\n",
    "        \n",
    "    # Define a cross-validation (shuffleSplit here)\n",
    "    ss = ShuffleSplit(n_splits, test_size=0.2, random_state=0)\n",
    "\n",
    "    for count, (training_indices, val_indices) in enumerate(ss.split(X, y), 1):\n",
    "        \n",
    "        if verbose > 1:\n",
    "            print(f'Cross-validation: {count}/{n_splits}')\n",
    "\n",
    "        # Prepare the test and training set     \n",
    "        X_train = X.iloc[training_indices,:]\n",
    "        y_train = y.iloc[training_indices]\n",
    "        X_val = X.iloc[val_indices,:]\n",
    "        y_val = y.iloc[val_indices]\n",
    "        if verbose > 1:\n",
    "            print(f\"The validation set corresponds to roughly {np.round(100*(len(X_val.index)/len(X.index)),2)}% of the total data.\") \n",
    "        \n",
    "        #Scaling the features -- useful for most classifier except RF and co\n",
    "        X_train, X_val = scale_data(X_train, X_val)\n",
    "        \n",
    "        if FS == \"RFE\":            \n",
    "            selector = RFE(estimator = LinearSVC())\n",
    "            selector = selector.fit(X_train, y_train)\n",
    "            X_train = X_train[X_train.columns[selector.support_]]\n",
    "            X_val = X_val[X_val.columns[selector.support_]]\n",
    "        elif FS == \"LASSO\":\n",
    "            X_train, X_val = lasso_feature_reduction(X_train, X_val, y_train)\n",
    "        elif FS == \"RF\":\n",
    "            X_train, X_val, impor = rf_feature_reduction(X_train, X_val, y_train)\n",
    "        elif (FS == \"None\") | (FS == \"PCA\"):\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Check your feature selection method. Enter either 'RFE', LASSO', 'RF' or 'None'.\")\n",
    "            return\n",
    "        \n",
    "        # Fit the classifier\n",
    "        clf.fit(X_train.values.tolist(), y_train.values)        \n",
    "        \n",
    "        # Predict the classes\n",
    "        y_pred = clf.predict(X_val.values.tolist())\n",
    "        \n",
    "        # Calculate the performance metrics \n",
    "        train_acc = accuracy_score(y_train.values.tolist(), clf.predict(X_train.values.tolist()))\n",
    "        val_acc = accuracy_score(y_val.values.tolist(), y_pred)\n",
    "        #roc_auc = roc_auc_score(y_val.values, clf.predict_proba(X_val.values)[:, 1])\n",
    "        \n",
    "        if verbose > 1:\n",
    "            print(f\"Training accuracy {count}: {train_acc}\")\n",
    "            print(f\"Validation accuracy {count}: {val_acc}\")\n",
    "            #print(f\"ROC AUC {count}: {roc_auc}\")\n",
    "    \n",
    "        # Add the performances to their corresponding lists\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        #rocs.append(roc_auc)\n",
    "    if verbose > 1:\n",
    "        print(\"_________________________________________________________________________________\")   \n",
    "    if verbose > 0:\n",
    "        print(f'\\tAverage Training Accuracy: {np.round(100*np.mean(train_accuracies), 2)} +/- {np.round(100*np.std(train_accuracies),2)}%.')\n",
    "        print(f'\\tAverage Validation Accuracy: {np.round(100*np.mean(val_accuracies),2)} +/- {np.round(100*np.std(val_accuracies),2)}%.')\n",
    "        #print(f'Average AUC {np.round(100*np.mean(np.array(rocs)),2)} +/- {np.round(100*np.std(np.array(rocs)),2)}%.')\n",
    "    \n",
    "    models_saved.append(clf)\n",
    "    \n",
    "    return 100*np.mean(train_accuracies), 100*np.std(train_accuracies), 100*np.mean(val_accuracies), 100*np.std(val_accuracies)#, 100*np.mean(np.array(rocs)), 100*np.std(np.array(rocs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_saved = []\n",
    "\n",
    "def run_all_drugs(DRUG_NAMES, PATH, SCORE, N_SPLITS, verbose = 5):\n",
    "    \n",
    "    final_results = pd.DataFrame()\n",
    "    \n",
    "    for drug in DRUG_NAMES:\n",
    "\n",
    "        print(f\"Investigating {drug}... \")\n",
    "\n",
    "        # Read the corresponding ML matrix\n",
    "        ML_matrix = pd.read_csv(PATH + f\"{drug}.csv\")\n",
    "        ML_matrix.set_index(\"Cell_line\", inplace = True)\n",
    "\n",
    "        print(\"Number of cells: \", len(ML_matrix.index))\n",
    "        if verbose > 3:\n",
    "            ML_matrix.head() #Show the head of the dataframe for that drug\n",
    "\n",
    "        results_drug = calculate_performances(drug, ML_matrix, PATH, SCORE, N_SPLITS, verbose = verbose)\n",
    "        \n",
    "        final_results = pd.concat([final_results,results_drug])\n",
    "                                          \n",
    "        print(\"_________________________________________________________________________________________________________\")\n",
    "        \n",
    "    final_results.index.name = \"Methods\"\n",
    "    \n",
    "    return final_results.reset_index(drop=False).set_index([\"Drug\",\"Methods\"])\n",
    "                                          \n",
    "final_results = run_all_drugs(DRUG_NAMES, PATH, SCORE, N_SPLITS, verbose = 0)\n",
    "display(final_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higest Performing Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CI-1040\n",
    "# Highest performing method: PCA & MLP\n",
    "ci_1040_PCA = #\n",
    "ci_1040_model = #\n",
    "    \n",
    "# PD0325901\n",
    "# Highest performing method: PCA & Logistic Regression\n",
    "pd0325901_PCA = #\n",
    "pd0325901_model = #\n",
    "\n",
    "# Refametinib\n",
    "# Highest performing method: PCA & Logistic Regression\n",
    "refametinib_PCA = #\n",
    "refametinib_model = #\n",
    "\n",
    "# VX-11e\n",
    "# Highest performing method: PCA & Logistic Regression\n",
    "vx_11e_PCA = #\n",
    "vx_11e_model = #\n",
    "\n",
    "# Afatinib\n",
    "# Highest performing method: None & MLP\n",
    "afatinib_PCA = None\n",
    "afatinib_model = #\n",
    "\n",
    "# Pelitinib\n",
    "# Highest performing method: PCA & Random Forest\n",
    "pelitinib_PCA = #\n",
    "pelitinib_model = #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with machine learning models and feature selection techniques\n",
    "\n",
    "models = {'CI-1040': [ci_1040_model, ci_1040_PCA],'PD0325901': \\\n",
    "          [pd0325901_model,pd0325901_PCA],'Refametinib': [refametinib_model,refametinib_PCA],\\\n",
    "          'VX-11e': [vx_11e_model, vx_11e_PCA],'Afatinib': [afatinib_model, afatinib_PCA],\\\n",
    "          'Pelitinib':[pelitinib_model, pelitinib_PCA]}\n",
    "\n",
    "\n",
    "# Takes in a .csv with one row of mutation data\n",
    "def predict(csv): \n",
    "    \n",
    "    patient_data = pandas.read_csv(csv)\n",
    "    results = []\n",
    "    \n",
    "    for i in models.keys():\n",
    "        \n",
    "        # If PCA is needed\n",
    "        if models.get(i[1]):\n",
    "            model_PCA = models.get(i[1])\n",
    "            patient_data = pd.DataFrame(model_PCA.fit_transform(patient_data, y=None))\n",
    "            patient_data.columns = [f\"PC{elem}\" for elem in range(len(patient_data.columns))]\n",
    "        \n",
    "        # Scale data, predict\n",
    "        patient_data = scale_data(patient_data)\n",
    "        clf = models.get(i[0])\n",
    "        result = clf.predict(patient_data.values.tolist())\n",
    "        probabilities = clf.predict_proba(patient_data.values.tolist())\n",
    "        results.append([i, result, [max(probabilities)]])\n",
    "    \n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

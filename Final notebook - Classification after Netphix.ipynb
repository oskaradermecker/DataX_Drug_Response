{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset\n",
    "\n",
    "Please note that before running the code, you will need all the GDSC files. They can be found on the drive (https://drive.google.com/drive/u/1/folders/11omvpOttkdZZgv_ppbtcCbojkuVR-D61) or directly on the GDSC website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE = \"AUC\" #how the sensitivity of the drug is computed; other option: \"AUC\" \n",
    "SAVE = False #whether to save the final matrix or not\n",
    "PATH = \"data/Final matrices/\" #where your data is located\n",
    "\n",
    "N_SPLITS = 5\n",
    "DRUG_NAMES = {\"CI-1040\": [\"MYC_mut\",\"RB1_mut\",\"ERBB2_amp\",\"BRAF_mut\",\"KRAS_mut\",\"NRAS_mut\"]#,\n",
    "              #\"PD0325901\": [\"MYC_mut\",\"RB1_mut\",\"ERBB2_amp\",\"BRAF_mut\",\"KRAS_mut\",\"NRAS_mut\"],\n",
    "              #\"Refametinib\":[\"MYC_mut\",\"RB1_mut\",\"ERBB2_amp\",\"BRAF_mut\",\"KRAS_mut\",\"NRAS_mut\"],\n",
    "              #\"VX-11e\":[\"RB1_mut\",\"ERBB2_amp\",\"CCND1_amp\",\"BRAF_mut\",\"KRAS_mut\",\"NRAS_mut\"],\n",
    "              #\"Afatinib\":[\"KRAS_mut\",\"NRAS_mut\",\"EGFR_amp\",\"ERBB2_amp\",\"FOXP3_del\"],\n",
    "              #\"Pelitinib\":[\"BRAF_mut\",\"RB1_mut\",\"MAPK1_del\",\"MYC_mut\",\"EGFR_mut\",\"CDKN1B_del\"]\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test):\n",
    "    \n",
    "    feature_names = list(X_train) # Store the feature names\n",
    "    \n",
    "    sc = StandardScaler()  # Defines the scaler\n",
    "    X_train = pd.DataFrame(sc.fit_transform(X_train))  # Scales the training data\n",
    "    X_test = pd.DataFrame(sc.transform(X_test))  # Scales the validation data\n",
    "\n",
    "    # Replace feature names in the database (they are lost during scaling)\n",
    "    X_train.columns = feature_names\n",
    "    X_test.columns = feature_names\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_feature_reduction(X_train, X_val, y_train, Cst = 0.01):\n",
    "    \n",
    "    clf = LinearSVC(C = Cst, penalty = \"l1\", dual = False) #SVC(kernel = 'linear', C = Cst)\n",
    "    clf.fit(X_train.values, y_train)\n",
    "    \n",
    "    model = SelectFromModel(clf, prefit=True, threshold=-np.inf, max_features = 300)\n",
    "    new_X_train = model.transform(X_train.values)\n",
    "    new_X_val = model.transform(X_val.values)\n",
    "    \n",
    "    return pd.DataFrame(new_X_train), pd.DataFrame(new_X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feature_reduction(X_train, X_val, y_train, N_ESTIMATORS = 500):\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators = N_ESTIMATORS, n_jobs = -1, class_weight = \"balanced\", random_state = 32)\n",
    "    clf = clf.fit(X_train.values, y_train.values)\n",
    "    \n",
    "    model = SelectFromModel(clf, prefit=True, threshold=-np.inf, max_features = 300)   \n",
    "    new_X_train = model.transform(X_train)\n",
    "    new_X_val = model.transform(X_val)\n",
    "    \n",
    "    importances = clf.feature_importances_\n",
    "    #std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0) --> std dev but we don't use it anyway\n",
    "    \n",
    "    return pd.DataFrame(new_X_train), pd.DataFrame(new_X_val), importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_PCA(X, NB_COMPONENTS, kf = 5, verbose = 5):\n",
    "\n",
    "    if verbose > 1:\n",
    "        print(\"Running PCA...\")\n",
    "        print(\"Number of features before PCA: \", len(X.columns))\n",
    "\n",
    "    # Starting PCA\n",
    "    my_PCA = PCA(n_components=NB_COMPONENTS)\n",
    "    reduced_X = pd.DataFrame(my_PCA.fit_transform(np.array(X.values), y=None))\n",
    "    reduced_X.columns = [f\"PC{elem}\" for elem in range(NB_COMPONENTS)]\n",
    "    \n",
    "    # Plotting\n",
    "    if verbose > 0:\n",
    "        fig = plt.figure()\n",
    "        g = sns.lineplot(x = range(1, NB_COMPONENTS+1), y = my_PCA.explained_variance_ratio_)\n",
    "        plt.xlabel('Principal Component')\n",
    "        plt.ylabel('Variance (Component Scores)')\n",
    "        plt.title('Screen Plot of Principal Components')\n",
    "        plt.show(); \n",
    "    \n",
    "    if verbose > 1:\n",
    "        print(\"Number of combined features after PCA: \",len(list(reduced_X)))\n",
    "    \n",
    "    return reduced_X   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performances(DRUG_NAME, ML_matrix, PATH, SCORE, N_SPLITS, verbose = 5):\n",
    "    \n",
    "    ## Look at the distribution of the response\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print(f\"\\nDistribution of responses for {DRUG_NAME}\")\n",
    "        fig = plt.figure(figsize = (10,6))\n",
    "        sns.distplot(ML_matrix[[DRUG_NAME]])\n",
    "        plt.title(\"Plot of the distribution of AUC values for \"+ DRUG_NAME)\n",
    "        plt.xlabel(\"AUC\")\n",
    "        plt.ylabel(\"Proportion of cell poplations\")\n",
    "        plt.grid(True);\n",
    "        plt.show()\n",
    "\n",
    "    #_______________________________________________________________________________________________________#\n",
    "    \n",
    "    ## Data Categorisation and feature matrix preparation\n",
    "    print(\"\\nCategorisation of the data...\")\n",
    "    # The data is divided in quartiles. Upper/lower third quartile thresholds were used for discretization. \n",
    "    # Everything that is in the middle is discarded. See [this](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3995541/) paper.\n",
    "    # Splitting at the median or mean, although keeping more cells, leads to poorer results.\n",
    "    \n",
    "    if verbose > 1:\n",
    "        print(\"The lower threshold used here is the lower third quartile = \", ML_matrix[DRUG_NAME].quantile([0.25,0.75])[0.25])\n",
    "        print(\"The upper threshold used here is the uppder third quartile = \", ML_matrix[DRUG_NAME].quantile([0.25,0.75])[0.75])\n",
    "    #ML_matrix[\"Response\"] = pd.cut(ML_matrix[DRUG_NAME], [np.min(ML_matrix[DRUG_NAME]), ML_matrix[DRUG_NAME].quantile([0.25,0.75])[0.25], ML_matrix[DRUG_NAME].quantile([0.25,0.75])[0.75], np.max(ML_matrix[DRUG_NAME])], labels = [\"sensitive\",\"medium\", \"resistant\"])\n",
    "    ML_matrix[\"Response\"] = pd.cut(ML_matrix[DRUG_NAME], [np.min(ML_matrix[DRUG_NAME]), np.mean(ML_matrix[DRUG_NAME]) - 0.5*np.std(ML_matrix[DRUG_NAME]), np.mean(ML_matrix[DRUG_NAME]) + 0.5*np.std(ML_matrix[DRUG_NAME]), np.max(ML_matrix[DRUG_NAME])], labels = [\"sensitive\",\"medium\",\"resistant\"])\n",
    "    ML_matrix = ML_matrix.drop([DRUG_NAME], axis = 1)\n",
    "    \n",
    "    #Drop all the \"medium\" classes and NaNs\n",
    "    ML_matrix = ML_matrix.drop(ML_matrix[ML_matrix[\"Response\"] == \"medium\"].index)  \n",
    "    \n",
    "    # Convert the response to a float\n",
    "    ML_matrix[\"Response\"] = [0 if x=='resistant' else 1 for x in ML_matrix['Response']]\n",
    "    \n",
    "    # Structure of the feature matrix\n",
    "    print(f\"\\tStructure of the final matrix for {DRUG_NAME}:\")\n",
    "    print(\"\\t\\tNumber of resistant cells: \", len(ML_matrix[ML_matrix[\"Response\"] == 0]))\n",
    "    print(\"\\t\\tNumber of sensitive cells: \", len(ML_matrix[ML_matrix[\"Response\"] == 1]))\n",
    "    print(\"\\t\\tTotal number of cells: \", len(ML_matrix.index))\n",
    "    print(f'\\n\\t\\tThe baseline accuracy for {DRUG_NAME} is {100*np.round(max(len(ML_matrix[ML_matrix[\"Response\"] == 1])/len(ML_matrix.index),len(ML_matrix[ML_matrix[\"Response\"] == 0])/len(ML_matrix.index)),2)}%')\n",
    "    \n",
    "    #_______________________________________________________________________________________________________#\n",
    "    \n",
    "    ## Run the different models and feature selection methods\n",
    "    \n",
    "    print(f\"\\nRunning the models with a {N_SPLITS}-fold cross-validation...\")\n",
    "    print(\"Please wait. This can take up to a minute.\")\n",
    "    \n",
    "    # Create our feature and response matrix\n",
    "    X = ML_matrix.drop(\"Response\", axis = 1)\n",
    "    y = ML_matrix[\"Response\"].astype('float64')\n",
    "        \n",
    "    # Define our models    \n",
    "    models = [SVC(random_state=40, probability = True),\n",
    "              LogisticRegression(solver= 'saga', max_iter=5000, random_state=41),\n",
    "              MLPClassifier(max_iter=5000, random_state=42),\n",
    "              RandomForestClassifier(n_estimators=300, max_depth = 3, max_leaf_nodes = 10, random_state=43)]\n",
    "    \n",
    "    model_names = ['SVM', 'Logistic Regression', 'MLP', 'Random Forest']\n",
    "    \n",
    "    # Define our final result matrix\n",
    "    final_results = pd.DataFrame(columns = model_names)     \n",
    "          \n",
    "    # Run all models\n",
    "    # Run PCA\n",
    "    final_results = pretty_run(final_results, X, y, models, model_names, N_SPLITS, DRUG_NAME, FS = \"PCA\", index_name = \"Principal Component Analysis\", verbose = verbose)  \n",
    "          \n",
    "    # Run RFE\n",
    "    final_results = pretty_run(final_results, X, y, models, model_names, N_SPLITS, DRUG_NAME, FS = \"RFE\", index_name = \"Recursive Feature Elimination\", verbose = verbose)\n",
    "    \n",
    "    # Run Lasso Feature Selection\n",
    "    final_results = pretty_run(final_results, X, y, models, model_names, N_SPLITS, DRUG_NAME, FS = \"LASSO\", index_name = \"Lasso Feature Selection\", verbose = verbose)\n",
    "          \n",
    "    # Run Random Forest Feature Selection\n",
    "    final_results = pretty_run(final_results, X, y, models, model_names, N_SPLITS, DRUG_NAME, FS = \"RF\", index_name = \"Random Forest Feature Selection\", verbose = verbose)\n",
    "          \n",
    "    # Run with no feature selection\n",
    "    final_results = pretty_run(final_results, X, y, models, model_names, N_SPLITS, DRUG_NAME, FS = \"None\", index_name = \"No feature selection\", verbose = verbose)\n",
    "    \n",
    "    print(f\"All the models were run on {DRUG_NAME} successfully!\")\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_run(final_results, X, y, models, model_names, N_SPLITS, DRUG_NAME, FS, index_name, verbose = 5):\n",
    "    \n",
    "    for i in range(len(models)):\n",
    "        if verbose > 0:\n",
    "            print('______________________\\n')\n",
    "            print('Running',model_names[i],'and',index_name)\n",
    "        perf = run_model(X, y, models[i], FS = FS, n_splits = N_SPLITS, verbose = verbose)\n",
    "        final_results.loc[index_name,model_names[i]] = perf[2]\n",
    "    \n",
    "    final_results.loc[index_name,\"Drug\"] = DRUG_NAME\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X, y, clf, FS = \"None\", n_splits = 5, verbose = 5):\n",
    "    \n",
    "    train_accuracies, val_accuracies, rocs = [],[],[]\n",
    "    \n",
    "    if FS == \"PCA\":\n",
    "        X = run_PCA(X, NB_COMPONENTS = len(X.columns), verbose = verbose)\n",
    "        \n",
    "    # Define a cross-validation (shuffleSplit here)\n",
    "    ss = ShuffleSplit(n_splits, test_size=0.2, random_state=0)\n",
    "\n",
    "    for count, (training_indices, val_indices) in enumerate(ss.split(X, y), 1):\n",
    "        \n",
    "        if verbose > 1:\n",
    "            print(f'Cross-validation: {count}/{n_splits}')\n",
    "\n",
    "        # Prepare the test and training set     \n",
    "        X_train = X.iloc[training_indices,:]\n",
    "        y_train = y.iloc[training_indices]\n",
    "        X_val = X.iloc[val_indices,:]\n",
    "        y_val = y.iloc[val_indices]\n",
    "        if verbose > 1:\n",
    "            print(f\"The validation set corresponds to roughly {np.round(100*(len(X_val.index)/len(X.index)),2)}% of the total data.\") \n",
    "        \n",
    "        #Scaling the features -- useful for most classifier except RF and co\n",
    "        X_train, X_val = scale_data(X_train, X_val)\n",
    "        \n",
    "        if FS == \"RFE\":            \n",
    "            selector = RFE(estimator = LinearSVC())\n",
    "            selector = selector.fit(X_train, y_train)\n",
    "            X_train = X_train[X_train.columns[selector.support_]]\n",
    "            X_val = X_val[X_val.columns[selector.support_]]\n",
    "        elif FS == \"LASSO\":\n",
    "            X_train, X_val = lasso_feature_reduction(X_train, X_val, y_train)\n",
    "        elif FS == \"RF\":\n",
    "            X_train, X_val, impor = rf_feature_reduction(X_train, X_val, y_train)\n",
    "        elif (FS == \"None\") | (FS == \"PCA\"):\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Check your feature selection method. Enter either 'RFE', LASSO', 'RF' or 'None'.\")\n",
    "            return\n",
    "        \n",
    "        # Fit the classifier\n",
    "        clf.fit(X_train.values.tolist(), y_train.values)        \n",
    "        \n",
    "        # Predict the classes\n",
    "        y_pred = clf.predict(X_val.values.tolist())\n",
    "        \n",
    "        # Calculate the performance metrics \n",
    "        train_acc = accuracy_score(y_train.values.tolist(), clf.predict(X_train.values.tolist()))\n",
    "        val_acc = accuracy_score(y_val.values.tolist(), y_pred)\n",
    "        roc_auc = roc_auc_score(y_val.values, clf.predict_proba(X_val.values)[:, 1])\n",
    "        \n",
    "        if verbose > 1:\n",
    "            print(f\"Training accuracy {count}: {train_acc}\")\n",
    "            print(f\"Validation accuracy {count}: {val_acc}\")\n",
    "            print(f\"ROC AUC {count}: {roc_auc}\")\n",
    "    \n",
    "        # Add the performances to their corresponding lists\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "        rocs.append(roc_auc)\n",
    "    if verbose > 1:\n",
    "        print(\"_________________________________________________________________________________\")   \n",
    "    if verbose > 0:\n",
    "        print(f'\\tAverage Training Accuracy: {np.round(100*np.mean(train_accuracies), 2)} +/- {np.round(100*np.std(train_accuracies),2)}%.')\n",
    "        print(f'\\tAverage Validation Accuracy: {np.round(100*np.mean(val_accuracies),2)} +/- {np.round(100*np.std(val_accuracies),2)}%.')\n",
    "        print(f'\\tAverage AUC {np.round(100*np.mean(np.array(rocs)),2)} +/- {np.round(100*np.std(np.array(rocs)),2)}%.')\n",
    "    \n",
    "    return 100*np.mean(train_accuracies), 100*np.std(train_accuracies), 100*np.mean(val_accuracies), 100*np.std(val_accuracies), 100*np.mean(np.array(rocs)), 100*np.std(np.array(rocs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating CI-1040... \n",
      "Number of cells:  758\n",
      "\n",
      "Categorisation of the data...\n",
      "\tStructure of the final matrix for CI-1040:\n",
      "\t\tNumber of resistant cells:  287\n",
      "\t\tNumber of sensitive cells:  164\n",
      "\t\tTotal number of cells:  451\n",
      "\n",
      "\t\tThe baseline accuracy for CI-1040 is 64.0%\n",
      "\n",
      "Running the models with a 5-fold cross-validation...\n",
      "Please wait. This can take up to a minute.\n",
      "All the models were run on CI-1040 successfully!\n",
      "_________________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>MLP</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug</th>\n",
       "      <th>Methods</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">CI-1040</th>\n",
       "      <th>Principal Component Analysis</th>\n",
       "      <td>81.7582</td>\n",
       "      <td>81.978</td>\n",
       "      <td>81.978</td>\n",
       "      <td>81.5385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recursive Feature Elimination</th>\n",
       "      <td>81.0989</td>\n",
       "      <td>81.0989</td>\n",
       "      <td>81.0989</td>\n",
       "      <td>80.8791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Feature Selection</th>\n",
       "      <td>81.7582</td>\n",
       "      <td>81.978</td>\n",
       "      <td>81.5385</td>\n",
       "      <td>82.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Feature Selection</th>\n",
       "      <td>81.7582</td>\n",
       "      <td>81.978</td>\n",
       "      <td>81.5385</td>\n",
       "      <td>82.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No feature selection</th>\n",
       "      <td>81.7582</td>\n",
       "      <td>81.978</td>\n",
       "      <td>81.5385</td>\n",
       "      <td>82.4176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             SVM Logistic Regression      MLP  \\\n",
       "Drug    Methods                                                                 \n",
       "CI-1040 Principal Component Analysis     81.7582              81.978   81.978   \n",
       "        Recursive Feature Elimination    81.0989             81.0989  81.0989   \n",
       "        Lasso Feature Selection          81.7582              81.978  81.5385   \n",
       "        Random Forest Feature Selection  81.7582              81.978  81.5385   \n",
       "        No feature selection             81.7582              81.978  81.5385   \n",
       "\n",
       "                                        Random Forest  \n",
       "Drug    Methods                                        \n",
       "CI-1040 Principal Component Analysis          81.5385  \n",
       "        Recursive Feature Elimination         80.8791  \n",
       "        Lasso Feature Selection               82.4176  \n",
       "        Random Forest Feature Selection       82.4176  \n",
       "        No feature selection                  82.4176  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_all_drugs(DRUG_NAMES, PATH, SCORE, N_SPLITS, verbose = 5):\n",
    "    \n",
    "    final_results = pd.DataFrame()\n",
    "    \n",
    "    for drug in DRUG_NAMES:\n",
    "\n",
    "        print(f\"Investigating {drug}... \")\n",
    "\n",
    "        # Read the corresponding ML matrix\n",
    "        ML_matrix = pd.read_csv(PATH + f\"{drug}.csv\")\n",
    "        ML_matrix.set_index(\"Cell_line\", inplace = True)\n",
    "        ML_matrix = ML_matrix.dropna()\n",
    "\n",
    "        print(\"Number of cells: \", len(ML_matrix.index))\n",
    "        if verbose > 3:\n",
    "            ML_matrix.head() #Show the head of the dataframe for that drug\n",
    "\n",
    "        results_drug = calculate_performances(drug, ML_matrix, PATH, SCORE, N_SPLITS, verbose = verbose)\n",
    "        \n",
    "        final_results = pd.concat([final_results,results_drug])\n",
    "                                          \n",
    "        print(\"_________________________________________________________________________________________________________\")\n",
    "        \n",
    "    final_results.index.name = \"Methods\"\n",
    "    \n",
    "    return final_results.reset_index(drop=False).set_index([\"Drug\",\"Methods\"])\n",
    "                                          \n",
    "final_results = run_all_drugs(DRUG_NAMES, PATH, SCORE, N_SPLITS, verbose = 0)\n",
    "display(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_results.to_csv(f'data/Results/Netphix_results.csv', index_label = [\"Drug\",\"Methods\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing with the code -- Not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRUG_NAME = \"CI-1040\"\n",
    "\n",
    "# ML_matrix = pd.read_csv(PATH + f\"CI-1040.csv\")\n",
    "# ML_matrix.set_index(\"Cell_line\", inplace = True)\n",
    "\n",
    "# ML_matrix[\"Response\"] = pd.cut(ML_matrix[DRUG_NAME], [np.min(ML_matrix[DRUG_NAME]), ML_matrix[DRUG_NAME].quantile([0.25,0.75])[0.25], ML_matrix[DRUG_NAME].quantile([0.25,0.75])[0.75], np.max(ML_matrix[DRUG_NAME])], labels = [\"sensitive\",\"medium\", \"resistant\"])\n",
    "# ML_matrix = ML_matrix.drop([DRUG_NAME], axis = 1)\n",
    "    \n",
    "# #Drop all the \"medium\" classes and NaNs\n",
    "# ML_matrix = ML_matrix.drop(ML_matrix[ML_matrix[\"Response\"] == \"medium\"].index)\n",
    "# ML_matrix = ML_matrix.dropna()  \n",
    "\n",
    "# # Convert the response to a float\n",
    "# ML_matrix[\"Response\"] = [0 if x=='resistant' else 1 for x in ML_matrix['Response']]\n",
    "\n",
    "# X = ML_matrix.drop(\"Response\", axis = 1)\n",
    "# #X = X[X.columns[[False,False,False,True,True,True]]]\n",
    "# y = ML_matrix[\"Response\"].astype('float64')\n",
    "        \n",
    "#     # Define our models    \n",
    "# svm = SVC(random_state=40)\n",
    "# lr = LogisticRegression(solver= 'saga', max_iter=5000, random_state=41)\n",
    "# mlp = MLPClassifier(max_iter=5000, random_state=42)\n",
    "# rf = RandomForestClassifier(n_estimators=300, max_depth = 3, max_leaf_nodes = 10, random_state=43)\n",
    "\n",
    "# svm_scores = cross_val_score(svm,X,y,cv=5)  # fit + predict + eval. \n",
    "# print('SVM Average Accuracy:', str(round(svm_scores.mean()*100,3)),'%')\n",
    "# lr_scores = cross_val_score(lr,X,y,cv=5)  # fit + predict + eval. \n",
    "# print('LR Average Accuracy:', str(round(lr_scores.mean()*100,3)),'%')\n",
    "# mlp_scores = cross_val_score(mlp,X,y,cv=5)  # fit + predict + eval. \n",
    "# print('Perceptron Average Accuracy:', str(round(mlp_scores.mean()*100,3)),'%')\n",
    "# rf_scores = cross_val_score(rf,X,y,cv=5)  # fit + predict + eval. \n",
    "# print('RF Average Accuracy:', str(round(rf_scores.mean()*100,3)),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Major Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - None of the methods of feature selection have lead to satisfying results. Alternative solutions have to be investigated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The GDSC portal provides a list of 659 features that are frequently altered in cancer and are correlated with drug sensitivity. We will use these to add different weights to features.\n",
    "- We will experiment with Pearson's coefficient, Spearman's correlation and Elastic Net in feature selection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
